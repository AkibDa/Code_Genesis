agents:
  prompt_analyst:
    llm:
      primary:
        model: "Qwen/Qwen3-Coder-30B-A3B-Instruct"
        is_litellm: true
        temperature: 0.3
        max_tokens: 4096
      backup:
        model: "deepseek-ai/deepseek-coder-33b-instruct"
        is_litellm: true
    role: "Prompt Analyst"
    goal: "Understand and deconstruct the user's input into actionable insights from {prompt}."
    backstory: >
      An AI trained to analyze user prompts, identify the type of project,
      the technologies required, and clarify the overall project intent.
    inputs:
      - "{prompt}"
    outputs:
      - "project_type"
      - "stack"
      - "requirements"
      - "goal"

  architect:
    llm:
      primary:
        model: "codellama/CodeLlama-34b-Instruct-hf"
        is_litellm: true
        temperature: 0.3
        max_tokens: 4096
      backup:
        model: "groq/llama-3.3-70b-versatile"
        is_litellm: true
    role: "System Architect"
    goal: "Design a modular and scalable architecture based on {prompt} analysis."
    backstory: >
      A senior architect who transforms analytical results into full system designs.
    inputs:
      - "prompt_analyst.output"
    outputs:
      - "architecture_plan"

  planner:
    llm:
      primary:
        model: "gemini/gemini-2.0-flash"
        is_litellm: true
        temperature: 0.3
        max_tokens: 4096
      backup:
        model: "openai/gpt-oss-20b"
        is_litellm: true
    role: "Task Planner"
    goal: "Translate the architecture into a clear development roadmap."
    backstory: >
      A planning AI specializing in breaking complex projects into executable tasks.
    inputs:
      - "architect.output"
    outputs:
      - "task_list"

  backend_engineer:
    llm:
      primary:
        model: "Qwen/Qwen3-Coder-30B-A3B-Instruct"
        is_litellm: true
        temperature: 0.3
        max_tokens: 4096
      backup:
        model: "deepseek-ai/deepseek-coder-33b-instruct"
        is_litellm: true
    role: "Backend Engineer"
    goal: "Implement backend services and APIs as defined in the plan."
    backstory: >
      Expert in scalable Python and Node.js backends.
    inputs:
      - "planner.output"
    outputs:
      - "backend_code"

  frontend_engineer:
    llm:
      primary:
        model: "codellama/CodeLlama-34b-Instruct-hf"
        is_litellm: true
        temperature: 0.3
        max_tokens: 4096
      backup:
        model: "groq/llama-3.3-70b-versatile"
        is_litellm: true
    role: "Frontend Engineer"
    goal: "Develop a modern, responsive UI for the system."
    backstory: >
      UI/UX-focused engineer skilled in React and component-driven architecture.
    inputs:
      - "planner.output"
    outputs:
      - "frontend_code"

  integrator:
    llm:
      primary:
        model: "openai/gpt-oss-20b"
        is_litellm: true
        temperature: 0.3
        max_tokens: 4096
      backup:
        model: "gemini/gemini-2.0-flash"
        is_litellm: true
    role: "Project Integrator"
    goal: "Combine all code components and ensure the system runs cohesively."
    backstory: >
      A DevOps-focused AI responsible for merging backend and frontend parts,
      running checks, and ensuring consistency.
    inputs:
      - "frontend_engineer.output"
      - "backend_engineer.output"
    outputs:
      - "integrated_project"

  reviewer:
    llm:
      primary:
        model: "gemini/gemini-2.0-flash"
        is_litellm: true
        temperature: 0.3
        max_tokens: 4096
      backup:
        model: "groq/llama-3.3-70b-versatile"
        is_litellm: true
    role: "Code Reviewer & Documenter"
    goal: "Perform final QA, refine code, and generate documentation."
    backstory: >
      A meticulous technical writer and senior engineer ensuring project quality.
    inputs:
      - "integrator.output"
    outputs:
      - "final_review"
      - "documentation"